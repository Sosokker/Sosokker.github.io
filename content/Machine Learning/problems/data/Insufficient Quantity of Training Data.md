----
# Explanation

If you want toddler to learn what apple is, you just point at apple and say "apple" and repeat a few times. Now the child can recognize apples in almost all sorts of colors and shapes.

Machine Learning is not quite there yet; it takes *a lot of data* for most ML algorithm to work properly.

In a 2001 [paper](https://dl.acm.org/doi/10.3115/1073012.1073017), Microsoft researchers Banko and Brill demonstrated that different machine learning algorithms, including fairly simple ones, performed almost identically well on a complex problem of natural language disambiguation once they were *given enough data*. This led them to suggest reevaluating the balance between investing in algorithm development versus corpus development (acquiring more data).

The notion that data plays a more significant role than algorithms in solving complex problems gained further recognition in a 2009 paper by Norvig et al. titled "[The Unreasonable Effectiveness of Data.](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf)" However, it's important to note that obtaining large datasets is not always easy or inexpensive, as small and medium-sized datasets are still prevalent. Therefore, algorithms remain crucial, and abandoning them entirely is not recommended.

*NOTE*
disambiguation : For example, knowing whether to write “to”, “two”, or “too”, depending on the context.
